input {
    jdbc {
        jdbc_connection_string => "jdbc:postgresql://postgres:5432/search"
        jdbc_user => "search"
        jdbc_password => "admin"
        jdbc_paging_enabled => true
        jdbc_page_size => 100
        jdbc_driver_class => "org.postgresql.Driver"
        #jdbc_driver_library => "postgresql-42.2.12.jar"
        #SELECT keys.* FROM mytable, json_object_keys(mytable.data) AS keys (mykey);
        statement => 'SELECT DISTINCT ON (r.uuid) r.uuid as id, CAST(data as text), s.id as source_id,
                        s.name as source_name, s.url as source_url, last_updated,
                        (SELECT COUNT(*) from "references_metadata" WHERE source = r.source) AS source_total_count,
						(SELECT CAST(ARRAY_TO_JSON(ARRAY_AGG(ROW_TO_JSON(c))) AS TEXT) FROM collections AS c WHERE c.uuid = ANY(ARRAY(SELECT cr.collection_uuid FROM collections_references AS cr WHERE cr.reference_uuid = r.uuid))) as collection_json
                        FROM "references_metadata" r LEFT JOIN sources s ON (r.source = s.id) 
                        WHERE
							last_updated > :sql_last_value OR 
							(SELECT MAX(cr.last_updated) FROM collections_references AS cr WHERE cr.reference_uuid = r.uuid GROUP BY cr.reference_uuid) > :sql_last_value
                        ORDER BY r.uuid, last_updated DESC'
        tracking_column => "last_modified"
        tracking_column_type => "timestamp"
        use_column_value => false

        ## every 15 seconds
        schedule => "*/15 * * * * *"
        lowercase_column_names => false
    }
}
filter {
    mutate {
        rename => {"source_id" => "[source][id]"}
        rename => {"source_name" => "[source][name]"}
        rename => {"source_url" => "[source][url]"}
        rename => {"source_total_count" => "[source][total_count]"}
    }
    json {
        source => "data"
    }
    json {
        source => "collection_json"
        target => "collection"
    }
    prune {
        blacklist_names => [ "collection_json", "data", "type", "doc", "@version", "@timestamp" ]
    }
}
output {
    #stdout { }
    elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "search_idx"
        action => update
        document_id => "%{[id]}"
        doc_as_upsert => true
        #user => "elastic"
        #password => "changethisinproduction"
        # seems not working properly, is now moved to docker-entrypoint
        #template => "/usr/share/logstash/templates/elastic-index.json"
        #template_name => "search_idx"
        #template_overwrite => true
    }
}